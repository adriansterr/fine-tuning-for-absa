models:
  - model: "D:/Uni/Masterarbeit Code/jakob_finetuning/finetuned_models/meta_llama_full_colab_remerge_2"
    parameters:
      weight: 1.0
      density: 0.8
      epsilon: 0.1
  - model: "Nos-PT/Llama-Carvalho-PT-GL"
    parameters:
      weight: 0.8
      density: 0.8
      epsilon: 0.1

base_model: "unsloth/Meta-Llama-3.1-8B-Instruct"

merge_method: della_linear
dtype: bfloat16

parameters:
  lambda: 1.0